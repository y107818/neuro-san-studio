# Copyright © 2025 Cognizant Technology Solutions Corp, www.cognizant.com.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# END COPYRIGHT

# To use this agent network, start by installing the required package:
#     pip install wikipedia

{
    "llm_config": {
        "model_name": "bedrock-us-claude-sonnet-4",
    },

    # Optional metadata describing this agent network
    "metadata": {
        "description": "Wikipedia RAG assistant that retrieves and answers queries using relevant Wikipedia articles, supporting multiple languages and configurable retrieval parameters.",
        "tags": ["rag", "wikipedia", "tool"],
        "sample_queries": [
            "Compare ResNet, DenseNet, and EfficientNet for image classification",
            "Tell me about the history of artificial intelligence",
            "What is quantum computing?",
        ]
    },

    "tools": [
        {
            "name": "Wikipedia_RAG_Assistant",

            "function": {
              "description": "Answer caller's query with answers from tools.",
            },

            "instructions": """Always use your tool to respond to the inquiry.
            If the tool failed or unavailable, just notify the user.
            Do not attempt to answer the question by yourself.""",

            "tools": ["rag_retriever"]
        },
        # RAG tool that retrieves relevant pages from Wikipedia to answer queries.
        {
            "name": "rag_retriever",

            "toolbox": "wikipedia_rag",

            "args": {
                # User-defined arguments for the tool

                # --- Optional Arguments ---

                # Wikipedia language edition to use
                # e.g., "en" for English, "es" for Spanish, "fr" for French
                "lang": "en",

                # Maximum number of Wikipedia pages to load per query term
                # Start small and increase the value only if answers lack context
                # Recommended values:
                # Focused Q&A (well-known topic): 3–5
                # Broader overview / brainstorming / research scan: 8–12
                "top_k_results": "3",

                # Per-document character cap to keep long pages from inflating context/cost
                # Token math: ~1 token ≈ 4 chars
                # Total doc tokens ≈ (K * doc_content_chars_max) / 4  (K = top_k_results)
                # Budget docs to a small share of the model’s max tokens (aim ~6–10%, increase if answers lack context)
                # Need more coverage? lower per-doc cap; Need more detail per doc? lower K
                "doc_content_chars_max": "4000",
            }
        }
    ]
}
